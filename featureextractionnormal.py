# -*- coding: utf-8 -*-
"""FeatureExtractionNormal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o7IcmuqRTFqXHWuZN2WDo-qE7-IGkhTY
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import urllib
import sys
import os
import zipfile
import torch.nn as nn
import torch.nn.functional as F
import torch
import torch.optim as optim
from torch.autograd import Variable
from torch.utils.data import Dataset, DataLoader, random_split

import torchvision
from torchvision.datasets import FashionMNIST
from torchvision import transforms
import pandas as pd
from google.colab import drive
from scipy.stats import skew
from scipy.stats import kurtosis
from sklearn import svm
from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.svm import LinearSVC
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.svm import OneClassSVM
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import roc_auc_score

drive.mount('/content/drive')

zip_ref = zipfile.ZipFile("/content/drive/My Drive/SeqData.zip", 'r')
zip_ref.extractall("/home")
zip_ref.close()

!ls /home/ReadDataFolder

path = "/home/ReadDataFolder/"
def rearrangeData(dp):
  a = []
  for i in range(dp.shape[0]):
    a.append(dp[i,1:])
  return np.array(a)

def extractdata(fname):
  data =  pd.read_csv(path + fname,sep=' ',header=None)
  dataPoints = data.to_numpy()[:,1:] #rearrangeData(data.to_numpy())
  v = np.sum(dataPoints[-1,12:])
  return dataPoints, v


normal100 = []
normal300 = []
normal1500= []
failed100 = []
failed300 = [] 
failed1500= []

normal100Type = []
normal300Type = []
normal1500Type = []
failed100Type = []
failed300Type = [] 
failed1500Type = []

normal100id = []
normal300id = []
normal1500id = []
failed100id = []
failed300id = [] 
failed1500id = []

v_str = []
count = 0
for filename in os.listdir(path):
  s1 = filename.split('.')[1]
  s2 = s1.split('_')[0]
  id = int(s2)
  if filename[-2] == 'N':
    datap, v = extractdata(filename)
    v_str.append(v)
    if datap.shape[0] == 100:
      normal100.append(datap)
      normal100Type.append(filename[-2:])
      normal100id.append(id)
    elif datap.shape[0] == 300:
      normal300.append(datap)
      normal300Type.append(filename[-2:])
      normal300id.append(id)
    else:
      normal1500.append(datap)
      normal1500Type.append(filename[-2:])
      normal1500id.append(id)
  else:
    datap, v = extractdata(filename)
    #if not (v < 8 and filename[-2] == 'T'):
    if (v<8): 
      if datap.shape[0] == 100:
        failed100.append(datap)
        failed100Type.append(filename[-2:])
        failed100id.append(id)
      elif datap.shape[0] == 300:
        failed300.append(datap)
        failed300Type.append(filename[-2:])
        failed300id.append(id)
      else:
        failed1500.append(datap)
        failed1500Type.append(filename[-2:])
        failed1500id.append(id)
    #else:
    #  count += 1

print(count)

normal100 = np.array(normal100)
failed100 = np.array(failed100)
normal300 = np.array(normal300)
failed300 = np.array(failed300)
normal1500= np.array(normal1500)
failed1500= np.array(failed1500)

print(normal300.shape)
print(failed300.shape)
print(normal1500.shape)
print(failed1500.shape)

print(5284 + 1181 + 1757 + 184)
print((1181 + 184)/(5284 + 1181 + 1757 + 184))

p = 5

plt.plot(failed1500[p][:,0],failed1500[p][:,1])
plt.plot(failed1500[p][:,0],failed1500[p][:,2])
plt.plot(failed1500[p][:,0],failed1500[p][:,3])
plt.plot(failed1500[p][:,0],failed1500[p][:,4])
plt.show()

plt.plot(failed1500[p][:,0],failed1500[p][:,5])
plt.plot(failed1500[p][:,0],failed1500[p][:,6])
plt.plot(failed1500[p][:,0],failed1500[p][:,7])
plt.show()

plt.plot(failed1500[p][:,0],failed1500[p][:,8])
plt.plot(failed1500[p][:,0],failed1500[p][:,9])
plt.plot(failed1500[p][:,0],failed1500[p][:,10])
plt.plot(failed1500[p][:,0],failed1500[p][:,11])
plt.show()

plt.plot(failed1500[p][:,0],failed1500[p][:,12])
plt.plot(failed1500[p][:,0],failed1500[p][:,13])
plt.plot(failed1500[p][:,0],failed1500[p][:,14])
plt.plot(failed1500[p][:,0],failed1500[p][:,15])
plt.plot(failed1500[p][:,0],failed1500[p][:,16])
plt.plot(failed1500[p][:,0],failed1500[p][:,17])
plt.plot(failed1500[p][:,0],failed1500[p][:,18])
plt.plot(failed1500[p][:,0],failed1500[p][:,19])
plt.show()

seqlength = 100
overlap = 1.0
dataCollection = []
dataType = []
dataId = []

for i in range(normal300.shape[0]):
  ldata = normal300[i]
  ldata[1:,11:] = ldata[1:,11:]-ldata[:-1,11:]
  ltype = normal300Type[i]
  lid = normal300id[i]
  for j in range(0,ldata.shape[0]-seqlength,int(seqlength*overlap)):
    dataCollection.append(ldata[j:j+seqlength][:])
    dataType.append(ltype)
    dataId.append(lid)

for i in range(normal1500.shape[0]):
  ldata = normal1500[i]
  ldata[1:,11:] = ldata[1:,11:]-ldata[:-1,11:]
  ltype = normal1500Type[i]
  lid = normal1500id[i]
  for j in range(0,ldata.shape[0]-seqlength,int(seqlength*overlap)):
    dataCollection.append(ldata[j:j+seqlength][:])
    dataType.append(ltype)
    dataId.append(lid)

for i in range(failed300.shape[0]):
  ldata = failed300[i]
  ldata[1:,11:] = ldata[1:,11:]-ldata[:-1,11:]
  ltype = failed300Type[i]
  lid = failed300id[i]
  for j in range(0,ldata.shape[0]-seqlength,int(seqlength*overlap)):
    dataCollection.append(ldata[j:j+seqlength][:])
    dataType.append(ltype)
    dataId.append(lid)

for i in range(failed1500.shape[0]):
  ldata = failed1500[i]
  ldata[1:,11:] = ldata[1:,11:]-ldata[:-1,11:]
  ltype = failed1500Type[i]
  lid = failed1500id[i]
  for j in range(0,ldata.shape[0]-seqlength,int(seqlength*overlap)):
    dataCollection.append(ldata[j:j+seqlength][:])
    dataType.append(ltype)
    dataId.append(lid)

dataCollection = np.array(dataCollection)
print(dataCollection.shape)
print(dataType)
print(dataId)

def extractFeatures(dp):
  f = []
  eps = 1e-16
  for i in range(1,dp.shape[1]):
    # temporal
    M = np.mean(dp[:,i]) # mean
    AM = np.mean(np.absolute(dp[:,i])) # absolute mean
    RMS = np.sqrt(np.mean(np.power(dp[:,i],2))) # RMS
    AVP = np.mean(np.power(dp[:,i],2)) # Average power
    ROA = np.mean(np.sqrt(np.absolute(dp[:,i])))**2.0 # Root Amplitude
    PE = np.max(np.absolute(dp[:,i])) # peak
    PEP = np.max(dp[:,i]) - np.min(dp[:,i]) # peak 2 peak
    VA = np.var(dp[:,i]) # variance
    STD = np.std(dp[:,i]) # standard dev
    SK = skew(dp[:,i]) # skewness
    KU = kurtosis(dp[:,i]) # kurtosis

    WAI = (RMS+eps)/(AM+eps)
    IMI = (PE+eps)/(AM+eps)
    CRI = (PE+eps)/(RMS+eps)
    MAI = (PE+eps)/(ROA+eps)
    SKI = (SK+eps)/(STD**3+eps)
    KUI = (KU+eps)/(STD**4+eps)

    #frequency
    xd = dp[1:,i]-dp[:-1,i]
    FC = (np.dot(dp[1:,i],xd) + eps)/(2.0*np.pi*np.dot(dp[:,i],dp[:,i]) + eps)
    MSF = (np.dot(xd,xd) + eps)/(4.0*(np.pi**2)*np.dot(dp[:,i],dp[:,i]) + eps)
    RMSF = np.sqrt(MSF)
    VF = MSF - FC**2
    RVF = np.sqrt(np.absolute(VF))

    #f = f + [M,AM,RMS,AVP,ROA,PE,PEP,VA,STD,SK,KU,WAI,CRI,IMI,MAI,SKI,KUI,FC,MSF,RMSF,VF,RVF]
    f = f + [M,AM,RMS,ROA,PEP,STD,SK,KU,WAI,CRI,IMI,MAI,FC,MSF,RMSF,VF,RVF]

  return np.array(f)

X = []
id = []
classname = []
for i in range(len(dataCollection)):
  dp = dataCollection[i]
  features = extractFeatures(dp)
  X.append(features)
  id.append(dataId[i])
  if dataType[i][0] == 'N':
    classname.append(0)
  else:
    classname.append(1)

data = np.array(X)
classes = np.array(classname)
id = np.array(id)

idx = np.random.permutation(data.shape[0])
Xt,y, ids = data[idx], classes[idx],id[idx]

print(Xt.shape,y.shape,ids.shape)
print(y)

max_arr = np.amax(Xt,axis=0)
i = 0
error_itr = []
for ele in max_arr:
  if abs(ele) > 1e6:
    print(i%22)
  i+=1

np.save('TSF_4.npy', Xt) # save
np.save('TSC_4.npy', y)
np.save('TSI_4.npy',ids)